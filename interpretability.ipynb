{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import random\n",
    "from datetime import datetime\n",
    "import json\n",
    "import training\n",
    "import color\n",
    "import vector as vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('nextpostest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights_to_txt(model, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        for layer in model.layers:\n",
    "            f.write(f\"Layer [{layer.name}] weights ({len(layer.get_weights())}):\\n\")\n",
    "            for weight_array in layer.get_weights():\n",
    "                for weight in weight_array:\n",
    "                    f.write(str(weight) + \" \")\n",
    "                f.write(\"\\n\\n\")\n",
    "        f.write(\"End of weights.\\n\")\n",
    "\n",
    "save_weights_to_txt(model, 'weights_output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1, 32, 520) dtype=float32, numpy=\n",
      "array([[[0.69980425, 0.42932147, 0.9561626 , ..., 0.38285524,\n",
      "         0.52253747, 0.7145602 ],\n",
      "        [0.9101493 , 0.92315733, 0.26411974, ..., 0.86894214,\n",
      "         0.41241315, 0.74032277],\n",
      "        [0.64918005, 0.69404894, 0.89555573, ..., 0.801248  ,\n",
      "         0.8825641 , 0.60303587],\n",
      "        ...,\n",
      "        [0.85862243, 0.72139347, 0.03957549, ..., 0.51730573,\n",
      "         0.07013358, 0.36612839],\n",
      "        [0.50967735, 0.19668612, 0.82911795, ..., 0.7018368 ,\n",
      "         0.7101354 , 0.5572531 ],\n",
      "        [0.45872322, 0.42739886, 0.43451893, ..., 0.89625174,\n",
      "         0.03602418, 0.5867767 ]]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Ensure we're in eager execution mode\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "# Choose the layer and neuron you want to visualize\n",
    "layer_name = 'softmax'  # Second Dense layer\n",
    "neuron_index = 230\n",
    "\n",
    "# Start from random input data\n",
    "input_data_value = tf.Variable(np.random.random((1, 32, 520)).astype(np.float32), tf.float32)\n",
    "input_data_value_2 = tf.Variable(np.random.random((1, 32, 520)).astype(np.float32), tf.float32)\n",
    "\n",
    "# Run gradient ascent repeatedly\n",
    "step = 0.1\n",
    "for _ in range(4000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_data_value)\n",
    "        output = model([input_data_value, input_data_value_2])\n",
    "        loss = tf.reduce_mean(output[:, :, neuron_index])\n",
    "        \n",
    "    grads = tape.gradient(loss, input_data_value)\n",
    "    \n",
    "    # Normalize the gradients and apply the update to input_data_value\n",
    "    grads /= tf.math.reduce_std(grads) + 1e-8\n",
    "    # input_data_value += grads.numpy() * step\n",
    "    input_data_value.assign_add(grads.numpy() * step)\n",
    "\n",
    "print(input_data_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
