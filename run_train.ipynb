{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# Network Structure\n",
    "CONTEXT_SIZE = 8        # How many other voxels are considered for a training example\n",
    "EMBEDDING_SIZE = 64     # Dimensionality of the voxel embedding vector\n",
    "STACKED_LAYERS = 2      # How many times the network structure repeats itself\n",
    "ATTENTION_HEADS = 2     # Number of heads in each multi-headed attention mechanism\n",
    "\n",
    "# Training Hyperparameters\n",
    "CHECK_RADIUS = 7        # How far away voxels can be to be part of a training example\n",
    "CENTER_FOCUS = 0.3      # How much to focus on picking voxels close to the center of the cube. Must be between 0 and 1.\n",
    "LEARNING_RATE = 1e-4\n",
    "TRAINING_EXAMPLES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palette has 256 colors\n"
     ]
    }
   ],
   "source": [
    "# Load voxel palette\n",
    "# The output is a 255-dimensional vector of probabilities for different colors\n",
    "# Which 255 colors can be generated is decided by the palette file\n",
    "\n",
    "# Index 0 is reserved as 'undecided' voxel\n",
    "# Index 1 is reserved as 'air' voxel\n",
    "# Index 2-255 are colors. So there are 254 possible colors.\n",
    "with open('data/palette.json', 'r') as json_file:\n",
    "    palette = json.load(json_file)['colors']\n",
    "    palette_size = len(palette)\n",
    "\n",
    "print(f\"Palette has {palette_size} colors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_layer (InputLayer)       [(None, 8, 64)]      0           []                               \n",
      "                                                                                                  \n",
      " normalization_0a (LayerNormali  (None, 8, 64)       128         ['input_layer[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " residual_connection_0a (Add)   (None, 8, 64)        0           ['input_layer[0][0]',            \n",
      "                                                                  'normalization_0a[0][0]']       \n",
      "                                                                                                  \n",
      " feedforward_0 (Dense)          (None, 8, 64)        4160        ['residual_connection_0a[0][0]'] \n",
      "                                                                                                  \n",
      " relu_0 (LeakyReLU)             (None, 8, 64)        0           ['feedforward_0[0][0]']          \n",
      "                                                                                                  \n",
      " normalization_0b (LayerNormali  (None, 8, 64)       128         ['relu_0[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " residual_connection_0b (Add)   (None, 8, 64)        0           ['residual_connection_0a[0][0]', \n",
      "                                                                  'normalization_0b[0][0]']       \n",
      "                                                                                                  \n",
      " normalization_1a (LayerNormali  (None, 8, 64)       128         ['residual_connection_0b[0][0]'] \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " residual_connection_1a (Add)   (None, 8, 64)        0           ['residual_connection_0b[0][0]', \n",
      "                                                                  'normalization_1a[0][0]']       \n",
      "                                                                                                  \n",
      " feedforward_1 (Dense)          (None, 8, 64)        4160        ['residual_connection_1a[0][0]'] \n",
      "                                                                                                  \n",
      " relu_1 (LeakyReLU)             (None, 8, 64)        0           ['feedforward_1[0][0]']          \n",
      "                                                                                                  \n",
      " normalization_1b (LayerNormali  (None, 8, 64)       128         ['relu_1[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " residual_connection_1b (Add)   (None, 8, 64)        0           ['residual_connection_1a[0][0]', \n",
      "                                                                  'normalization_1b[0][0]']       \n",
      "                                                                                                  \n",
      " feedforward_final (Dense)      (None, 8, 255)       16575       ['residual_connection_1b[0][0]'] \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 8, 255)       0           ['feedforward_final[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,407\n",
      "Trainable params: 25,407\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "def main_model():\n",
    "    input = keras.Input(shape=(CONTEXT_SIZE, EMBEDDING_SIZE,), name='input_layer')\n",
    "\n",
    "    x = input\n",
    "\n",
    "    # Stacked layers\n",
    "    for i in range(STACKED_LAYERS):\n",
    "        # Multi-headed attention\n",
    "        fx = keras.layers.MultiHeadAttention(\n",
    "            num_heads=ATTENTION_HEADS,\n",
    "            key_dim=EMBEDDING_SIZE,\n",
    "            name=f'multi_head_attention_{i}',\n",
    "        )(x, x)\n",
    "\n",
    "        # Normalization\n",
    "        fx = keras.layers.LayerNormalization(name=f'normalization_{i}a')(x)\n",
    "\n",
    "        # Residual connection\n",
    "        x = keras.layers.Add(name=f'residual_connection_{i}a')([x,fx])\n",
    "\n",
    "        # Feedforward\n",
    "        fx = keras.layers.Dense(EMBEDDING_SIZE, name=f'feedforward_{i}')(x)\n",
    "        fx = keras.layers.LeakyReLU(name=f'relu_{i}')(fx)\n",
    "\n",
    "        # Normalization\n",
    "        fx = keras.layers.LayerNormalization(name=f'normalization_{i}b')(fx)\n",
    "\n",
    "        # Residual connection\n",
    "        x = keras.layers.Add(name=f'residual_connection_{i}b')([x,fx])\n",
    "    \n",
    "    # Final feedforward layer\n",
    "    # Output size should be palette_size-1, since we don't want it to be able to choose \"undecided\"\n",
    "    x = keras.layers.Dense(palette_size-1, name='feedforward_final')(x)\n",
    "\n",
    "    # Softmax\n",
    "    x = keras.layers.Softmax(name='softmax')(x)\n",
    "    \n",
    "    # Build and return model\n",
    "    return keras.Model(inputs=input, outputs=x)\n",
    "\n",
    "model = main_model()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loss and optimizer\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(pos, dim, size):\n",
    "    w = pos/(10000**((2*dim)/size))\n",
    "    if dim % 2 == 0:\n",
    "        w = math.sin(w)\n",
    "    else:\n",
    "        w = math.cos(w)\n",
    "    return w\n",
    "\n",
    "# Define embedding function\n",
    "def embed(position, index):\n",
    "    # Get rgb value\n",
    "    if index <= 1:\n",
    "        rgb = (-10, -10, -10)\n",
    "    else:\n",
    "        rgb = palette[index]\n",
    "        rgb[0] /= 255\n",
    "        rgb[1] /= 255\n",
    "        rgb[2] /= 255\n",
    "\n",
    "    # Spread rgb across the embedding size (r, g, b, r, g, b, r, g, b, etc.)\n",
    "    scale = int((EMBEDDING_SIZE+2)/3)\n",
    "    embedding = list(rgb) * scale\n",
    "\n",
    "    # Cut off the remainder\n",
    "    while len(embedding) > EMBEDDING_SIZE:\n",
    "        embedding.pop()\n",
    "\n",
    "    # Add positional encoding\n",
    "    dimension_length = int(EMBEDDING_SIZE / 3)\n",
    "    for i in range(dimension_length):\n",
    "        # X\n",
    "        embedding[i] += encode(position[0], i, dimension_length)\n",
    "        # Y\n",
    "        embedding[i + dimension_length] += encode(position[1], i, dimension_length)\n",
    "        # Z\n",
    "        embedding[i + dimension_length*2] += encode(position[2], i, dimension_length)\n",
    "    \n",
    "    # Return\n",
    "    return embedding\n",
    "\n",
    "# Encode a palette index into a one-hot-encoded output vector\n",
    "def encode_one_hot(index):\n",
    "    # Change UNDECIDED into AIR\n",
    "    if index < 1:\n",
    "        index = 1\n",
    "    \n",
    "    # Create the zeros vector\n",
    "    ret = np.zeros((palette_size-1,))\n",
    "\n",
    "    # Add the one at the right index\n",
    "    # We remove the zero index because the model should never output UNDECIDED\n",
    "    ret[index-1] = 1.0\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 training examples created.\n",
      "[((7, 5, 7), 247), ((9, 7, 8), 247), ((8, 2, 8), 247), ((6, -1, 9), 247), ((6, 1, 9), 247), ((7, 0, 8), 247), ((2, 2, 2), 247), ((2, 1, 2), 247), ((2, 2, 1), 247)]\n",
      "[[0.4121184852417566, -0.8241971521534709, 0.9999072470297011, 0.7974632995076811, 0.2661742906796119, 0.9937269805470542, 0.04659839157698506, 0.9998120215418507, 0.00806526707599458, 0.9999943725485259, 0.0013954637489467698, 0.9999998315377371, 0.00024144261922937773, 0.9999999949569518, 4.1774299490365034e-05, 0.9999999998490324, 7.227771499189438e-06, 0.9999999999954806, 1.2505459449354991e-06, 0.9999999999998647, 2.1636892651589597e-07, 0.6569865987187891, -0.9736893839936586, 0.9360167858093346, 0.8757640820029914, 0.2080201664904841, 0.9962036408312902, 0.036248379994106544, 0.9998862832288925, 0.006273012371676211, 0.9999965957379703, 0.0010853608327887425, 0.9999998980907288, 0.0001877887045658654, 0.9999999969492671, 3.249112182957281e-05, 0.9999999999086739, 5.6216000549444545e-06, 0.9999999999972661, 9.726468460610439e-07, 0.9999999999999182, 1.682869428456974e-07, 0.9893582466233818, -0.9827412558688747, 0.9826333056377525, 0.8387849861302871, 0.23720350566833798, 0.9950424511435405, 0.041423941423471035, 0.9998514728341898, 0.007169142602553235, 0.9999955536177131, 0.0012404123057781272, 0.9999998668940138, 0.00021461566197484948, 0.9999999960153694, 3.713271066036892e-05, 0.999999999880717, 6.424685777069018e-06, 0.9999999999964292, 1.1115963954982822e-06, 0.9999999999998931, 1.9232793468079675e-07, 0.0], [0.9893582466233818, -0.9827412558688747, 0.9826333056377525, 0.8387849861302871, 0.23720350566833798, 0.9950424511435405, 0.041423941423471035, 0.9998514728341898, 0.007169142602553235, 0.9999955536177131, 0.0012404123057781272, 0.9999998668940138, 0.00021461566197484948, 0.9999999960153694, 3.713271066036892e-05, 0.999999999880717, 6.424685777069018e-06, 0.9999999999964292, 1.1115963954982822e-06, 0.9999999999998931, 1.9232793468079675e-07, 0.9092974268256817, 0.6734632827658151, 0.33917441093188044, 0.9896589229336701, 0.05983578302752343, 0.99968991287103, 0.010358764093390531, 0.9999907168366957, 0.0017923000443124668, 0.999999722100914, 0.0003101031509964001, 0.9999999916808757, 5.365391587985191e-05, 0.9999999997509605, 9.28317766709223e-06, 0.9999999999925449, 1.6061714442776135e-06, 0.9999999999997768, 2.778990988746242e-07, 0.9999999999999933, 4.8081983670199465e-08, 0.9893582466233818, -0.9827412558688747, 0.9826333056377525, 0.8387849861302871, 0.23720350566833798, 0.9950424511435405, 0.041423941423471035, 0.9998514728341898, 0.007169142602553235, 0.9999955536177131, 0.0012404123057781272, 0.9999998668940138, 0.00021461566197484948, 0.9999999960153694, 3.713271066036892e-05, 0.999999999880717, 6.424685777069018e-06, 0.9999999999964292, 1.1115963954982822e-06, 0.9999999999998931, 1.9232793468079675e-07, 0.0], [-0.27941549819892586, -0.7985852361423327, 0.8614497112847916, 0.9082091374905099, 0.17865042385710106, 0.9972103695683364, 0.031071846133150054, 0.9999164525643832, 0.005376877103032854, 0.9999974989091527, 0.000930309333706207, 0.999999925127882, 0.00016096174702173247, 0.9999999977586452, 2.7849532998076695e-05, 0.9999999999329033, 4.818514332816267e-06, 0.9999999999979914, 8.336972966237868e-07, 0.9999999999999398, 1.4424595101059793e-07, -0.8414709848078965, 0.914730365398956, -0.1721576192806334, 0.9974113802573314, -0.029931301987883425, 0.9999224752127112, -0.005179451521004037, 0.9999976792064809, -0.0008961503819989976, 0.9999999305252261, -0.0001550515773619969, 0.9999999979202189, -2.6826957949579443e-05, 0.9999999999377401, -4.641588833596115e-06, 0.9999999999981362, -8.030857221390657e-07, 0.9999999999999442, -1.3894954943731344e-07, 0.9999999999999983, -2.404099183509974e-08, 0.4121184852417566, -0.8241971521534709, 0.9999072470297011, 0.7974632995076811, 0.2661742906796119, 0.9937269805470542, 0.04659839157698506, 0.9998120215418507, 0.00806526707599458, 0.9999943725485259, 0.0013954637489467698, 0.9999998315377371, 0.00024144261922937773, 0.9999999949569518, 4.1774299490365034e-05, 0.9999999998490324, 7.227771499189438e-06, 0.9999999999954806, 1.2505459449354991e-06, 0.9999999999998647, 2.1636892651589597e-07, 0.0], [-0.27941549819892586, -0.7985852361423327, 0.8614497112847916, 0.9082091374905099, 0.17865042385710106, 0.9972103695683364, 0.031071846133150054, 0.9999164525643832, 0.005376877103032854, 0.9999974989091527, 0.000930309333706207, 0.999999925127882, 0.00016096174702173247, 0.9999999977586452, 2.7849532998076695e-05, 0.9999999999329033, 4.818514332816267e-06, 0.9999999999979914, 8.336972966237868e-07, 0.9999999999999398, 1.4424595101059793e-07, 0.8414709848078965, 0.914730365398956, 0.1721576192806334, 0.9974113802573314, 0.029931301987883425, 0.9999224752127112, 0.005179451521004037, 0.9999976792064809, 0.0008961503819989976, 0.9999999305252261, 0.0001550515773619969, 0.9999999979202189, 2.6826957949579443e-05, 0.9999999999377401, 4.641588833596115e-06, 0.9999999999981362, 8.030857221390657e-07, 0.9999999999999442, 1.3894954943731344e-07, 0.9999999999999983, 2.404099183509974e-08, 0.4121184852417566, -0.8241971521534709, 0.9999072470297011, 0.7974632995076811, 0.2661742906796119, 0.9937269805470542, 0.04659839157698506, 0.9998120215418507, 0.00806526707599458, 0.9999943725485259, 0.0013954637489467698, 0.9999998315377371, 0.00024144261922937773, 0.9999999949569518, 4.1774299490365034e-05, 0.9999999998490324, 7.227771499189438e-06, 0.9999999999954806, 1.2505459449354991e-06, 0.9999999999998647, 2.1636892651589597e-07, 0.0], [0.6569865987187891, -0.9736893839936586, 0.9360167858093346, 0.8757640820029914, 0.2080201664904841, 0.9962036408312902, 0.036248379994106544, 0.9998862832288925, 0.006273012371676211, 0.9999965957379703, 0.0010853608327887425, 0.9999998980907288, 0.0001877887045658654, 0.9999999969492671, 3.249112182957281e-05, 0.9999999999086739, 5.6216000549444545e-06, 0.9999999999972661, 9.726468460610439e-07, 0.9999999999999182, 1.682869428456974e-07, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.9893582466233818, -0.9827412558688747, 0.9826333056377525, 0.8387849861302871, 0.23720350566833798, 0.9950424511435405, 0.041423941423471035, 0.9998514728341898, 0.007169142602553235, 0.9999955536177131, 0.0012404123057781272, 0.9999998668940138, 0.00021461566197484948, 0.9999999960153694, 3.713271066036892e-05, 0.999999999880717, 6.424685777069018e-06, 0.9999999999964292, 1.1115963954982822e-06, 0.9999999999998931, 1.9232793468079675e-07, 0.0], [0.9092974268256817, 0.6734632827658151, 0.33917441093188044, 0.9896589229336701, 0.05983578302752343, 0.99968991287103, 0.010358764093390531, 0.9999907168366957, 0.0017923000443124668, 0.999999722100914, 0.0003101031509964001, 0.9999999916808757, 5.365391587985191e-05, 0.9999999997509605, 9.28317766709223e-06, 0.9999999999925449, 1.6061714442776135e-06, 0.9999999999997768, 2.778990988746242e-07, 0.9999999999999933, 4.8081983670199465e-08, 0.9092974268256817, 0.6734632827658151, 0.33917441093188044, 0.9896589229336701, 0.05983578302752343, 0.99968991287103, 0.010358764093390531, 0.9999907168366957, 0.0017923000443124668, 0.999999722100914, 0.0003101031509964001, 0.9999999916808757, 5.365391587985191e-05, 0.9999999997509605, 9.28317766709223e-06, 0.9999999999925449, 1.6061714442776135e-06, 0.9999999999997768, 2.778990988746242e-07, 0.9999999999999933, 4.8081983670199465e-08, 0.9092974268256817, 0.6734632827658151, 0.33917441093188044, 0.9896589229336701, 0.05983578302752343, 0.99968991287103, 0.010358764093390531, 0.9999907168366957, 0.0017923000443124668, 0.999999722100914, 0.0003101031509964001, 0.9999999916808757, 5.365391587985191e-05, 0.9999999997509605, 9.28317766709223e-06, 0.9999999999925449, 1.6061714442776135e-06, 0.9999999999997768, 2.778990988746242e-07, 0.9999999999999933, 4.8081983670199465e-08, 0.0], [0.9092974268256817, 0.6734632827658151, 0.33917441093188044, 0.9896589229336701, 0.05983578302752343, 0.99968991287103, 0.010358764093390531, 0.9999907168366957, 0.0017923000443124668, 0.999999722100914, 0.0003101031509964001, 0.9999999916808757, 5.365391587985191e-05, 0.9999999997509605, 9.28317766709223e-06, 0.9999999999925449, 1.6061714442776135e-06, 0.9999999999997768, 2.778990988746242e-07, 0.9999999999999933, 4.8081983670199465e-08, 0.8414709848078965, 0.914730365398956, 0.1721576192806334, 0.9974113802573314, 0.029931301987883425, 0.9999224752127112, 0.005179451521004037, 0.9999976792064809, 0.0008961503819989976, 0.9999999305252261, 0.0001550515773619969, 0.9999999979202189, 2.6826957949579443e-05, 0.9999999999377401, 4.641588833596115e-06, 0.9999999999981362, 8.030857221390657e-07, 0.9999999999999442, 1.3894954943731344e-07, 0.9999999999999983, 2.404099183509974e-08, 0.9092974268256817, 0.6734632827658151, 0.33917441093188044, 0.9896589229336701, 0.05983578302752343, 0.99968991287103, 0.010358764093390531, 0.9999907168366957, 0.0017923000443124668, 0.999999722100914, 0.0003101031509964001, 0.9999999916808757, 5.365391587985191e-05, 0.9999999997509605, 9.28317766709223e-06, 0.9999999999925449, 1.6061714442776135e-06, 0.9999999999997768, 2.778990988746242e-07, 0.9999999999999933, 4.8081983670199465e-08, 0.0], [0.9092974268256817, 0.6734632827658151, 0.33917441093188044, 0.9896589229336701, 0.05983578302752343, 0.99968991287103, 0.010358764093390531, 0.9999907168366957, 0.0017923000443124668, 0.999999722100914, 0.0003101031509964001, 0.9999999916808757, 5.365391587985191e-05, 0.9999999997509605, 9.28317766709223e-06, 0.9999999999925449, 1.6061714442776135e-06, 0.9999999999997768, 2.778990988746242e-07, 0.9999999999999933, 4.8081983670199465e-08, 0.9092974268256817, 0.6734632827658151, 0.33917441093188044, 0.9896589229336701, 0.05983578302752343, 0.99968991287103, 0.010358764093390531, 0.9999907168366957, 0.0017923000443124668, 0.999999722100914, 0.0003101031509964001, 0.9999999916808757, 5.365391587985191e-05, 0.9999999997509605, 9.28317766709223e-06, 0.9999999999925449, 1.6061714442776135e-06, 0.9999999999997768, 2.778990988746242e-07, 0.9999999999999933, 4.8081983670199465e-08, 0.8414709848078965, 0.914730365398956, 0.1721576192806334, 0.9974113802573314, 0.029931301987883425, 0.9999224752127112, 0.005179451521004037, 0.9999976792064809, 0.0008961503819989976, 0.9999999305252261, 0.0001550515773619969, 0.9999999979202189, 2.6826957949579443e-05, 0.9999999999377401, 4.641588833596115e-06, 0.9999999999981362, 8.030857221390657e-07, 0.9999999999999442, 1.3894954943731344e-07, 0.9999999999999983, 2.404099183509974e-08, 0.0]]\n",
      "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "# Design training examples\n",
    "training_examples = training.generate_training_examples(TRAINING_EXAMPLES, CONTEXT_SIZE)\n",
    "\n",
    "print(f\"{len(training_examples)} training examples created.\")\n",
    "print(training_examples[0])\n",
    "\n",
    "# Reformat training examples into tensor format\n",
    "training_inputs = []\n",
    "training_outputs = []\n",
    "for example in training_examples:\n",
    "    inputEntry = []\n",
    "    outputEntry = []\n",
    "    for voxel in example:\n",
    "        inputEntry.append(embed(voxel[0], voxel[1]))\n",
    "        outputEntry.append(encode_one_hot(voxel[1]))\n",
    "    \n",
    "    # Shift the output\n",
    "    inputEntry.pop(0)\n",
    "    outputEntry.pop(-1)\n",
    "\n",
    "    # Push to training example list\n",
    "    training_inputs.append(inputEntry)\n",
    "    training_outputs.append(outputEntry)\n",
    "\n",
    "training_input_tensor = tf.Variable(training_inputs, tf.float64)\n",
    "training_output_tensor = tf.Variable(training_outputs, tf.float64)\n",
    "\n",
    "print(training_inputs[0])\n",
    "print(training_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step\n",
    "@tf.function\n",
    "def train_step(input_data, output_data):\n",
    "    # Set up tape\n",
    "    with tf.GradientTape() as tape:\n",
    "      output = model(input_data, training=True)\n",
    "\n",
    "      loss = loss_function(output_data, output)\n",
    "\n",
    "      gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    # Evaluate\n",
    "    #input_data_test, output_data_test = generate_data(100)\n",
    "    #output = model(input_data_test, training=False)\n",
    "\n",
    "# Training loop\n",
    "def train(epochs):\n",
    "  # For each epoch...\n",
    "  for epoch in range(epochs):\n",
    "    \n",
    "    \n",
    "    # For each minibatch...\n",
    "    for _ in range(1):\n",
    "      train_step(training_examples)\n",
    "\n",
    "      print()\n",
    "\n",
    "  \n",
    "train(1000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
