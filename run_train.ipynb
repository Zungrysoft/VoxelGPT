{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import math\n",
    "import json\n",
    "import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# Network Structure\n",
    "CONTEXT_SIZE = 32       # How many other voxels are considered for a training example\n",
    "EMBEDDING_SIZE = 516    # Dimensionality of the voxel embedding vector\n",
    "STACKED_LAYERS = 2      # How many times the network structure repeats itself\n",
    "ATTENTION_HEADS = 4     # Number of heads in each multi-headed attention mechanism\n",
    "\n",
    "# Training Hyperparameters\n",
    "CHECK_RADIUS = 7        # How far away voxels can be to be part of a training example\n",
    "CENTER_FOCUS = 0.3      # How much to focus on picking voxels close to the center of the cube. Must be between 0 and 1.\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAINING_EXAMPLES = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palette has 256 colors\n"
     ]
    }
   ],
   "source": [
    "# Load voxel palette\n",
    "# The output is a 255-dimensional vector of probabilities for different colors\n",
    "# Which 255 colors can be generated is decided by the palette file\n",
    "\n",
    "# Index 0 is reserved as 'undecided' voxel\n",
    "# Index 1 is reserved as 'air' voxel\n",
    "# Index 2-255 are colors. So there are 254 possible colors.\n",
    "with open('data/palette.json', 'r') as json_file:\n",
    "    palette = json.load(json_file)['colors']\n",
    "    palette_size = len(palette)\n",
    "\n",
    "print(f\"Palette has {palette_size} colors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_layer (InputLayer)       [(None, 32, 516)]    0           []                               \n",
      "                                                                                                  \n",
      " normalization_start_a (LayerNo  (None, 32, 516)     1032        ['input_layer[0][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_0 (MultiH  (None, 32, 516)     4266804     ['normalization_start_a[0][0]',  \n",
      " eadAttention)                                                    'normalization_start_a[0][0]']  \n",
      "                                                                                                  \n",
      " residual_connection_0a (Add)   (None, 32, 516)      0           ['normalization_start_a[0][0]',  \n",
      "                                                                  'multi_head_attention_0[0][0]'] \n",
      "                                                                                                  \n",
      " normalization_0a (LayerNormali  (None, 32, 516)     1032        ['residual_connection_0a[0][0]'] \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " feedforward_0 (Dense)          (None, 32, 516)      266772      ['normalization_0a[0][0]']       \n",
      "                                                                                                  \n",
      " relu_0 (LeakyReLU)             (None, 32, 516)      0           ['feedforward_0[0][0]']          \n",
      "                                                                                                  \n",
      " residual_connection_0b (Add)   (None, 32, 516)      0           ['normalization_0a[0][0]',       \n",
      "                                                                  'relu_0[0][0]']                 \n",
      "                                                                                                  \n",
      " normalization_0b (LayerNormali  (None, 32, 516)     1032        ['residual_connection_0b[0][0]'] \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 32, 516)     4266804     ['normalization_0b[0][0]',       \n",
      " eadAttention)                                                    'normalization_0b[0][0]']       \n",
      "                                                                                                  \n",
      " residual_connection_1a (Add)   (None, 32, 516)      0           ['normalization_0b[0][0]',       \n",
      "                                                                  'multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " normalization_1a (LayerNormali  (None, 32, 516)     1032        ['residual_connection_1a[0][0]'] \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " feedforward_1 (Dense)          (None, 32, 516)      266772      ['normalization_1a[0][0]']       \n",
      "                                                                                                  \n",
      " relu_1 (LeakyReLU)             (None, 32, 516)      0           ['feedforward_1[0][0]']          \n",
      "                                                                                                  \n",
      " residual_connection_1b (Add)   (None, 32, 516)      0           ['normalization_1a[0][0]',       \n",
      "                                                                  'relu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " normalization_1b (LayerNormali  (None, 32, 516)     1032        ['residual_connection_1b[0][0]'] \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " feedforward_final (Dense)      (None, 32, 255)      131835      ['normalization_1b[0][0]']       \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 32, 255)      0           ['feedforward_final[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,204,147\n",
      "Trainable params: 9,204,147\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "def main_model():\n",
    "    input = keras.Input(shape=(CONTEXT_SIZE, EMBEDDING_SIZE,), name='input_layer')\n",
    "\n",
    "    # Normalization\n",
    "    x = keras.layers.LayerNormalization(name=f'normalization_start_a')(input)\n",
    "\n",
    "    # Stacked layers\n",
    "    for i in range(STACKED_LAYERS):\n",
    "        # Multi-headed attention\n",
    "        fx = keras.layers.MultiHeadAttention(\n",
    "            num_heads=ATTENTION_HEADS,\n",
    "            key_dim=EMBEDDING_SIZE,\n",
    "            name=f'multi_head_attention_{i}',\n",
    "        )(x, x, use_causal_mask=True)\n",
    "\n",
    "        # Residual connection\n",
    "        x = keras.layers.Add(name=f'residual_connection_{i}a')([x,fx])\n",
    "\n",
    "        # Normalization\n",
    "        x = keras.layers.LayerNormalization(name=f'normalization_{i}a')(x)\n",
    "\n",
    "        # Feedforward\n",
    "        fx = keras.layers.Dense(EMBEDDING_SIZE, name=f'feedforward_{i}')(x)\n",
    "        fx = keras.layers.LeakyReLU(name=f'relu_{i}')(fx)\n",
    "\n",
    "        # Residual connection\n",
    "        x = keras.layers.Add(name=f'residual_connection_{i}b')([x,fx])\n",
    "\n",
    "        # Normalization\n",
    "        x = keras.layers.LayerNormalization(name=f'normalization_{i}b')(x)\n",
    "    \n",
    "    # Final feedforward layer\n",
    "    # Output size should be palette_size-1, since we don't want it to be able to choose \"undecided\"\n",
    "    x = keras.layers.Dense(palette_size-1, name='feedforward_final')(x)\n",
    "\n",
    "    # Softmax\n",
    "    x = keras.layers.Softmax(name='softmax')(x)\n",
    "    \n",
    "    # Build and return model\n",
    "    return keras.Model(inputs=input, outputs=x)\n",
    "\n",
    "model = main_model()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loss and optimizer\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 training examples created.\n",
      "[((0, 4, 0), 182), ((1, 4, 0), 1), ((2, 4, 0), 1), ((3, 4, 0), 1), ((4, 4, 0), 182), ((0, 0, 1), 1), ((1, 0, 1), 1), ((2, 0, 1), 1), ((3, 0, 1), 1), ((4, 0, 1), 1), ((0, 1, 1), 1), ((1, 1, 1), 1), ((2, 1, 1), 1), ((3, 1, 1), 1), ((4, 1, 1), 1), ((0, 2, 1), 1), ((1, 2, 1), 1), ((2, 2, 1), 1), ((3, 2, 1), 1), ((4, 2, 1), 1), ((0, 3, 1), 1), ((1, 3, 1), 1), ((2, 3, 1), 1), ((3, 3, 1), 249), ((4, 3, 1), 1), ((0, 4, 1), 1), ((1, 4, 1), 1), ((2, 4, 1), 1), ((3, 4, 1), 1), ((4, 4, 1), 1), ((0, 0, 2), 1), ((1, 0, 2), 1), ((2, 0, 2), 1)]\n"
     ]
    }
   ],
   "source": [
    "# Design training examples\n",
    "training_examples = training.generate_training_examples(TRAINING_EXAMPLES, CONTEXT_SIZE)\n",
    "\n",
    "print(f\"{len(training_examples)} training examples created.\")\n",
    "\n",
    "print(random.choice(training_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_training_input(example):\n",
    "    inputEntry = []\n",
    "    for index, voxel in enumerate(example):\n",
    "        inputEntry.append(training.embed(index, voxel[0], voxel[1], palette, EMBEDDING_SIZE))\n",
    "    if len(inputEntry) < CONTEXT_SIZE:\n",
    "        zero_elem = [0,] * EMBEDDING_SIZE\n",
    "        inputEntry += [zero_elem,] * (CONTEXT_SIZE - len(inputEntry))\n",
    "\n",
    "    return inputEntry\n",
    "\n",
    "def encode_training_output(example):\n",
    "    outputEntry = []\n",
    "    for voxel in example:\n",
    "        outputEntry.append(training.encode_one_hot(voxel[1], palette_size))\n",
    "    return outputEntry\n",
    "\n",
    "# Reformat training examples into tensor format\n",
    "def encode_training_examples(training_examples):\n",
    "    training_inputs = []\n",
    "    training_outputs = []\n",
    "    for example in training_examples:\n",
    "        inputEntry = encode_training_input(example)\n",
    "        outputEntry = encode_training_output(example)\n",
    "        \n",
    "        # Shift the output\n",
    "        inputEntry.pop(-1)\n",
    "        outputEntry.pop(0)\n",
    "\n",
    "        # Push to training example list\n",
    "        training_inputs.append(inputEntry)\n",
    "        training_outputs.append(outputEntry)\n",
    "\n",
    "    training_input_tensor = tf.Variable(training_inputs, tf.float64)\n",
    "    training_output_tensor = tf.Variable(training_outputs, tf.float64)\n",
    "\n",
    "    return training_input_tensor, training_output_tensor\n",
    "\n",
    "training_input_tensor, training_output_tensor = encode_training_examples(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch training data\n",
    "dataset_input = tf.data.Dataset.from_tensor_slices(training_input_tensor)\n",
    "dataset_output = tf.data.Dataset.from_tensor_slices(training_output_tensor)\n",
    "\n",
    "training_input_batched = dataset_input.batch(128)\n",
    "training_output_batched = dataset_output.batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct an example sculpture using the model's current progress\n",
    "# TODO: Move this to a separate file so we can do multithreading and other improvements\n",
    "def build_sculpture(count, base=None, temperature=1.0):\n",
    "    # If a base wasn't specified, create one\n",
    "    # color = int(random.random() * 254) + 1\n",
    "    color = 182\n",
    "    voxels = {}\n",
    "    voxels['0,0,0'] = color\n",
    "    \n",
    "    # Build context vector for the sculpture\n",
    "    context = [((0, 0, 0), color)]\n",
    "\n",
    "    for i in range(count-1):\n",
    "        # Determine where the next voxel will go\n",
    "        # TODO: Encode this data into the model somehow\n",
    "        next_pos = training.pick_next_voxel(voxels, context)\n",
    "\n",
    "        # Get the output from the model\n",
    "        input_data = encode_training_input(context)\n",
    "        input_tensor = tf.Variable(input_data, tf.float64)\n",
    "        input_tensor = tf.reshape(input_tensor, [1, -1, EMBEDDING_SIZE])\n",
    "        output = model(input_tensor, training=False)\n",
    "        output_probabilities = output[0][len(context)-1]\n",
    "\n",
    "        # Pick which voxel to generate based on output probabilities\n",
    "        # TODO: Implement temperature\n",
    "        choice = random.random()\n",
    "        chosen_voxel = 1\n",
    "        for i in range(len(output_probabilities)):\n",
    "            choice -= output_probabilities[i]\n",
    "            if choice < 0:\n",
    "                chosen_voxel = i+1\n",
    "                break\n",
    "        # chosen_voxel = 1\n",
    "        # best = 0\n",
    "        # for i in range(len(output_probabilities)):\n",
    "        #     if output_probabilities[i] > best:\n",
    "        #         best = output_probabilities[i]\n",
    "        #         chosen_voxel = i+1\n",
    "        \n",
    "        # Build the voxel\n",
    "        voxels[training.ttos(next_pos)] = chosen_voxel\n",
    "        context.append((next_pos, chosen_voxel))\n",
    "        if len(context) > CONTEXT_SIZE:\n",
    "            context.pop(0)\n",
    "        \n",
    "    return voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for saving sculptures to json\n",
    "def save_sculpture(sculpture, filename):\n",
    "    json_data = {\n",
    "        \"size\": {\n",
    "            \"x\": 5,\n",
    "            \"y\": 5,\n",
    "            \"z\": 5,\n",
    "        },\n",
    "        \"voxels\": sculpture,\n",
    "    }\n",
    "    with open(filename, 'w') as output_file:\n",
    "        json.dump(json_data, output_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building example sculpture...\n",
      "Done\n",
      "Building example sculpture...\n",
      "Done\n",
      "Building example sculpture...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Training step\n",
    "@tf.function\n",
    "def train_step(input_data, output_data):\n",
    "    # Set up tape\n",
    "    with tf.GradientTape() as tape:\n",
    "      output = model(input_data, training=True)\n",
    "\n",
    "      loss = loss_function(output_data, output)\n",
    "\n",
    "      gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "# Training loop\n",
    "def train(epochs):\n",
    "  time_started = datetime.now()\n",
    "  example_time = 3\n",
    "  sculptures_made = 0\n",
    "\n",
    "  # Epochs\n",
    "  for epoch in range(epochs):\n",
    "    # Minibatches\n",
    "    for (batch_input, batch_output) in zip(training_input_batched, training_output_batched):\n",
    "      train_step(batch_input, batch_output)\n",
    "\n",
    "    # Print status\n",
    "    # print(f\"Completed Epoch {epoch}\")\n",
    "\n",
    "    # Check if we should output an example sculpture\n",
    "    if (datetime.now()-time_started).total_seconds() >= example_time:\n",
    "      print(\"Building example sculpture...\")\n",
    "      sculpture = build_sculpture(125)\n",
    "      sculptures_made += 1\n",
    "      sculpture_filename = f\"examples/json/example_{(time_started-datetime.utcfromtimestamp(0)).total_seconds()}_{sculptures_made}.json\"\n",
    "      save_sculpture(sculpture, sculpture_filename)\n",
    "      print(\"Done\")\n",
    "      example_time = (datetime.now()-time_started).total_seconds() * 1.3\n",
    "\n",
    "train(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    weights = layer.get_weights()\n",
    "    for j, weight in enumerate(weights):\n",
    "        np.savetxt(f'layer_{i}_[ {layer.name} ]_weight_{j}.txt', weight.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_input_tensor[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
