{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import json\n",
    "import training\n",
    "import color\n",
    "import vector as vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# Network Structure\n",
    "CONTEXT_SIZE = 32       # How many other voxels are considered for a training example\n",
    "EMBEDDING_SIZE = 520    # Dimensionality of the voxel embedding vector\n",
    "STACKED_LAYERS = 1      # How many times the network structure repeats itself\n",
    "ATTENTION_HEADS = 10    # Number of heads in each multi-headed attention mechanism\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Training Hyperparameters\n",
    "CHECK_RADIUS = 7        # How far away voxels can be to be part of a training example\n",
    "CENTER_FOCUS = 0.3      # How much to focus on picking voxels close to the center of the cube. Must be between 0 and 1.\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAINING_EXAMPLES = 1\n",
    "AIR_WEIGHT = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palette has 256 colors\n"
     ]
    }
   ],
   "source": [
    "# Load voxel palette\n",
    "# The output is a 255-dimensional vector of probabilities for different colors\n",
    "# Which 255 colors can be generated is decided by the palette file\n",
    "\n",
    "# Index 0 is reserved as 'undecided' voxel\n",
    "# Index 1 is reserved as 'air' voxel\n",
    "# Index 2-255 are colors. So there are 254 possible colors.\n",
    "with open('data/palette.json', 'r') as json_file:\n",
    "    raw_palette = json.load(json_file)['colors']\n",
    "    palette = color.expand_palette(raw_palette)\n",
    "    palette_size = len(palette)\n",
    "\n",
    "print(f\"Palette has {palette_size} colors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loss and optimizer\n",
    "def weighted_categorical_crossentropy():\n",
    "    weights = np.ones(palette_size-1).astype(np.float64) \n",
    "    weights[0] = AIR_WEIGHT\n",
    "    weights = tf.keras.backend.variable(weights, dtype=tf.float64)\n",
    "    weights_tiled = np.tile(weights, (BATCH_SIZE, CONTEXT_SIZE, 1))\n",
    "\n",
    "    loss_object = tf.losses.CategoricalCrossentropy()\n",
    "\n",
    "    # def loss(y_true, y_pred):\n",
    "    #     # Convert tensors to float64 for consistent data type operations\n",
    "    #     y_true = tf.cast(y_true, tf.float64)\n",
    "    #     y_pred = tf.cast(y_pred, tf.float64)\n",
    "        \n",
    "    #     # scale predictions so that the class probas of each sample sum to 1\n",
    "    #     y_pred /= tf.keras.backend.sum(y_pred, axis=-1, keepdims=True)\n",
    "    #     # clip to prevent NaN's and Inf's\n",
    "    #     y_pred = tf.keras.backend.clip(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "    #     # calculate loss and weight it\n",
    "    #     loss = y_true * tf.keras.backend.log(y_pred) * weights\n",
    "    #     loss = -tf.keras.backend.sum(loss, -1)\n",
    "    #     return loss\n",
    "\n",
    "    #     # return tf.keras.losses.categorical_crossentropy(y_true, y_pred) * (y_true * weights)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        # loss = loss_object(y_true=y_true, y_pred=y_pred, sample_weight=weights_tiled)\n",
    "        loss = loss_object(y_true=y_true, y_pred=y_pred)\n",
    "        return loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Use custom loss with the class weights\n",
    "loss_function = weighted_categorical_crossentropy()\n",
    "# loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 32, 520)]    0           []                               \n",
      "                                                                                                  \n",
      " normalization_start_a (LayerNo  (None, 32, 520)     1040        ['input[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " input_next_pos (InputLayer)    [(None, 32, 520)]    0           []                               \n",
      "                                                                                                  \n",
      " concatenate_next_pos (Concaten  (None, 32, 1040)    0           ['normalization_start_a[0][0]',  \n",
      " ate)                                                             'input_next_pos[0][0]']         \n",
      "                                                                                                  \n",
      " feedforward_final (Dense)      (None, 32, 255)      265455      ['concatenate_next_pos[0][0]']   \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 32, 255)      0           ['feedforward_final[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 266,495\n",
      "Trainable params: 266,495\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "# def main_model():\n",
    "#     input = keras.Input(shape=(CONTEXT_SIZE, EMBEDDING_SIZE,), name='input')\n",
    "#     input_next_pos = keras.Input(shape=(CONTEXT_SIZE, EMBEDDING_SIZE,), name='input_next_pos')\n",
    "\n",
    "#     # Normalization\n",
    "#     x = keras.layers.LayerNormalization(name=f'normalization_start_a')(input)\n",
    "\n",
    "#     # Stacked layers\n",
    "#     for i in range(STACKED_LAYERS):\n",
    "#         # Multi-headed attention\n",
    "#         fx = keras.layers.MultiHeadAttention(\n",
    "#             num_heads=ATTENTION_HEADS,\n",
    "#             key_dim=EMBEDDING_SIZE,\n",
    "#             name=f'multi_head_attention_{i}',\n",
    "#         )(x, x, use_causal_mask=True)\n",
    "\n",
    "#         # Residual connection\n",
    "#         x = keras.layers.Add(name=f'residual_connection_{i}a')([x,fx])\n",
    "\n",
    "#         # Normalization\n",
    "#         x = keras.layers.LayerNormalization(name=f'normalization_{i}a')(x)\n",
    "\n",
    "#         # Feedforward\n",
    "#         fx = keras.layers.Dense(EMBEDDING_SIZE, name=f'feedforward_{i}')(x)\n",
    "#         fx = keras.layers.LeakyReLU(name=f'relu_{i}')(fx)\n",
    "\n",
    "#         # Residual connection\n",
    "#         x = keras.layers.Add(name=f'residual_connection_{i}b')([x,fx])\n",
    "\n",
    "#         # Normalization\n",
    "#         x = keras.layers.LayerNormalization(name=f'normalization_{i}b')(x)\n",
    "    \n",
    "#     # Concatenate with next_pos input\n",
    "#     x = keras.layers.Concatenate(axis=2, name='concatenate_next_pos')([x,input_next_pos])\n",
    "\n",
    "#     # Final feedforward layer\n",
    "#     # Output size should be palette_size-1, since we don't want it to be able to choose \"undecided\"\n",
    "#     x = keras.layers.Dense(palette_size-1, name='feedforward_final')(x)\n",
    "\n",
    "#     # Softmax\n",
    "#     x = keras.layers.Softmax(name='softmax')(x)\n",
    "    \n",
    "#     # Build and return model\n",
    "#     return keras.Model(inputs=[input, input_next_pos], outputs=x)\n",
    "\n",
    "def main_model():\n",
    "    input = keras.Input(shape=(CONTEXT_SIZE, EMBEDDING_SIZE,), name='input')\n",
    "    input_next_pos = keras.Input(shape=(CONTEXT_SIZE, EMBEDDING_SIZE,), name='input_next_pos')\n",
    "\n",
    "    # Normalization\n",
    "    x = keras.layers.LayerNormalization(name=f'normalization_start_a')(input)\n",
    "    \n",
    "    # Concatenate with next_pos input\n",
    "    x = keras.layers.Concatenate(axis=2, name='concatenate_next_pos')([x,input_next_pos])\n",
    "\n",
    "    # Final feedforward layer\n",
    "    # Output size should be palette_size-1, since we don't want it to be able to choose \"undecided\"\n",
    "    x = keras.layers.Dense(palette_size-1, name='feedforward_final')(x)\n",
    "\n",
    "    # Softmax\n",
    "    x = keras.layers.Softmax(name='softmax')(x)\n",
    "    \n",
    "    # Build and return model\n",
    "    return keras.Model(inputs=[input, input_next_pos], outputs=x)\n",
    "\n",
    "model = main_model()\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training examples created.\n",
      "[((0, 1, 0), 246), ((1, 1, 0), 231), ((2, 1, 0), 246), ((3, 1, 0), 246), ((4, 1, 0), 231), ((0, 2, 0), 246), ((1, 2, 0), 246), ((2, 2, 0), 231), ((3, 2, 0), 246), ((4, 2, 0), 246), ((0, 3, 0), 231), ((1, 3, 0), 246), ((2, 3, 0), 246), ((3, 3, 0), 231), ((4, 3, 0), 246), ((0, 4, 0), 246), ((1, 4, 0), 231), ((2, 4, 0), 246), ((3, 4, 0), 246), ((4, 4, 0), 231), ((0, 0, 1), 246), ((1, 0, 1), 246), ((2, 0, 1), 252), ((3, 0, 1), 1), ((4, 0, 1), 1), ((0, 1, 1), 1), ((1, 1, 1), 1), ((2, 1, 1), 1), ((3, 1, 1), 1), ((4, 1, 1), 1), ((0, 2, 1), 1), ((1, 2, 1), 1), ((2, 2, 1), 1)]\n"
     ]
    }
   ],
   "source": [
    "# Design training examples\n",
    "training_examples = training.generate_training_examples(TRAINING_EXAMPLES, CONTEXT_SIZE)\n",
    "\n",
    "print(f\"{len(training_examples)} training examples created.\")\n",
    "\n",
    "print(random.choice(training_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_training_input(example):\n",
    "    inputEntry = []\n",
    "\n",
    "    # Encode context vector\n",
    "    for index, voxel in enumerate(example):\n",
    "        if len(inputEntry) < CONTEXT_SIZE+1:\n",
    "            inputEntry.append(training.embed(index, voxel[0], voxel[1], palette, EMBEDDING_SIZE))\n",
    "\n",
    "    # Pad remainder of context with zeros\n",
    "    if len(inputEntry) < CONTEXT_SIZE+1:\n",
    "        zero_elem = [0,] * EMBEDDING_SIZE\n",
    "        inputEntry += [zero_elem,] * ((CONTEXT_SIZE+1) - len(inputEntry))\n",
    "\n",
    "    return inputEntry\n",
    "\n",
    "def encode_training_input_next_pos(example, last_pos):\n",
    "    inputEntry = []\n",
    "\n",
    "    # Encode context vector\n",
    "    for index in range(len(example)):\n",
    "        pos = example[index][0]\n",
    "        if index < len(example)-1:\n",
    "            next_pos = example[index+1][0]\n",
    "        else:\n",
    "            next_pos = last_pos\n",
    "        if len(inputEntry) < CONTEXT_SIZE+1:\n",
    "            # inputEntry.append(training.embed_nptest(index, vec.subtract(next_pos, pos), -1, palette, EMBEDDING_SIZE))\n",
    "            inputEntry.append(training.embed_nptest(index, next_pos, -1, palette, EMBEDDING_SIZE))\n",
    "\n",
    "    # Pad remainder of context with zeros\n",
    "    if len(inputEntry) < CONTEXT_SIZE+1:\n",
    "        zero_elem = [0,] * EMBEDDING_SIZE\n",
    "        inputEntry += [zero_elem,] * ((CONTEXT_SIZE+1) - len(inputEntry))\n",
    "    \n",
    "    return inputEntry\n",
    "\n",
    "def encode_training_output(example):\n",
    "    outputEntry = []\n",
    "    for voxel in example:\n",
    "        outputEntry.append(training.encode_one_hot(voxel[1], palette_size))\n",
    "    return outputEntry\n",
    "\n",
    "# Reformat training examples into tensor format\n",
    "def encode_training_examples(training_examples):\n",
    "    training_inputs = []\n",
    "    training_inputs_next_pos = []\n",
    "    training_outputs = []\n",
    "    for example in training_examples:\n",
    "        input_entry = encode_training_input(example)\n",
    "        input_entry_next_pos = encode_training_input_next_pos(example, (0, 0, 0))\n",
    "        output_entry = encode_training_output(example)\n",
    "        \n",
    "        # Shift the output\n",
    "        input_entry.pop(-1)\n",
    "        input_entry_next_pos.pop(-1)\n",
    "        output_entry.pop(0)\n",
    "\n",
    "        # Push to training example list\n",
    "        training_inputs.append(input_entry)\n",
    "        training_inputs_next_pos.append(input_entry_next_pos)\n",
    "        training_outputs.append(output_entry)\n",
    "\n",
    "    training_input_tensor = tf.Variable(training_inputs, tf.float64)\n",
    "    training_input_next_pos_tensor = tf.Variable(training_inputs_next_pos, tf.float64)\n",
    "    training_output_tensor = tf.Variable(training_outputs, tf.float64)\n",
    "\n",
    "    return training_input_tensor, training_input_next_pos_tensor, training_output_tensor\n",
    "\n",
    "training_input_tensor, training_input_next_pos_tensor, training_output_tensor = encode_training_examples(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(training_input_next_pos_tensor[12][0])\n",
    "\n",
    "# print(len(training_input_tensor[0][0]))\n",
    "# print(len(training_input_next_pos_tensor[0][0]))\n",
    "# print(len(training_output_tensor[0][0]))\n",
    "\n",
    "\n",
    "# i = 17\n",
    "# position = training_examples[0][i][0]\n",
    "# print(position[0] + (position[1] * 5) + (position[2] * 5 * 5))\n",
    "# print(training_examples[0][i+1])\n",
    "# print(training_input_next_pos_tensor[0][i])\n",
    "# for j in range(EMBEDDING_SIZE):\n",
    "#     if int(training_input_next_pos_tensor[0][i][j]) > 0:\n",
    "#         print(j)\n",
    "#         break\n",
    "\n",
    "# for j in range(EMBEDDING_SIZE):\n",
    "#     if int(training_output_tensor[0][21][j]) > 0:\n",
    "#         print(j+1)\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch training data\n",
    "dataset_input = tf.data.Dataset.from_tensor_slices(training_input_tensor)\n",
    "dataset_input_next_pos = tf.data.Dataset.from_tensor_slices(training_input_next_pos_tensor)\n",
    "dataset_output = tf.data.Dataset.from_tensor_slices(training_output_tensor)\n",
    "\n",
    "training_input_batched = dataset_input.batch(BATCH_SIZE)\n",
    "training_input_next_pos_batched = dataset_input_next_pos.batch(BATCH_SIZE)\n",
    "training_output_batched = dataset_output.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Pos indices:  1 No No No No No No No No No No No No No No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 0\n",
      "Context at index: ((0, 0, 0), 229)\n",
      "Chosen voxel: 179.0\n",
      "\n",
      "Next Pos indices:  1 2 No No No No No No No No No No No No No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 1\n",
      "Context at index: ((1, 0, 0), 179)\n",
      "Chosen voxel: 134.0\n",
      "\n",
      "Next Pos indices:  1 2 3 No No No No No No No No No No No No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 2\n",
      "Context at index: ((2, 0, 0), 134)\n",
      "Chosen voxel: 202.0\n",
      "\n",
      "Next Pos indices:  1 2 3 4 No No No No No No No No No No No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 3\n",
      "Context at index: ((3, 0, 0), 202)\n",
      "Chosen voxel: 196.0\n",
      "\n",
      "Next Pos indices:  1 2 3 4 5 No No No No No No No No No No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 4\n",
      "Context at index: ((4, 0, 0), 196)\n",
      "Chosen voxel: 19.0\n",
      "\n",
      "Next Pos indices:  1 2 3 4 5 6 No No No No No No No No No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 5\n",
      "Context at index: ((0, 1, 0), 19)\n",
      "Chosen voxel: 248.0\n",
      "\n",
      "Next Pos indices:  1 2 3 4 5 6 7 No No No No No No No No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 6\n",
      "Context at index: ((1, 1, 0), 248)\n",
      "Chosen voxel: 17.0\n",
      "\n",
      "Next Pos indices:  1 2 3 4 5 6 7 8 No No No No No No No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 7\n",
      "Context at index: ((2, 1, 0), 17)\n",
      "Chosen voxel: 53.0\n",
      "\n",
      "Next Pos indices:  1 2 3 4 5 6 7 8 9 No No No No No No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 8\n",
      "Context at index: ((3, 1, 0), 53)\n",
      "Chosen voxel: 129.0\n",
      "\n",
      "Next Pos indices:  1 2 3 4 5 6 7 8 9 10 No No No No No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 9\n",
      "Context at index: ((4, 1, 0), 129)\n",
      "Chosen voxel: 98.0\n",
      "\n",
      "Next Pos indices:  1 2 3 4 5 6 7 8 9 10 11 No No No No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 10\n",
      "Context at index: ((0, 2, 0), 98)\n",
      "Chosen voxel: 222.0\n",
      "\n",
      "Next Pos indices:  1 2 3 4 5 6 7 8 9 10 11 12 No No No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 11\n",
      "Context at index: ((1, 2, 0), 222)\n",
      "Chosen voxel: 107.0\n",
      "\n",
      "Next Pos indices:  1 2 3 4 5 6 7 8 9 10 11 12 13 No No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 12\n",
      "Context at index: ((2, 2, 0), 107)\n",
      "Chosen voxel: 222.0\n",
      "\n",
      "Next Pos indices:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 No No No No No No No No No No No No No No No No No No No \n",
      "Context index: 13\n",
      "Context at index: ((3, 2, 0), 222)\n",
      "Chosen voxel: 222.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0,0,0': 229,\n",
       " '1,0,0': 179,\n",
       " '2,0,0': 134,\n",
       " '3,0,0': 202,\n",
       " '4,0,0': 196,\n",
       " '0,1,0': 19,\n",
       " '1,1,0': 248,\n",
       " '2,1,0': 17,\n",
       " '3,1,0': 53,\n",
       " '4,1,0': 129,\n",
       " '0,2,0': 98,\n",
       " '1,2,0': 222,\n",
       " '2,2,0': 107,\n",
       " '3,2,0': 222,\n",
       " '4,2,0': 222}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pick_weighted_random(probabilities):\n",
    "    choice = random.random()\n",
    "    for i in range(len(probabilities)):\n",
    "        choice -= probabilities[i]\n",
    "        if choice < 0:\n",
    "            return i + 1\n",
    "    return 1\n",
    "\n",
    "def pick_highest(probabilities):\n",
    "    chosen_voxel = 1\n",
    "    best = 0\n",
    "    for i in range(len(probabilities)):\n",
    "        if probabilities[i] > best:\n",
    "            best = probabilities[i]\n",
    "            chosen_voxel = i+1\n",
    "    \n",
    "    return chosen_voxel\n",
    "\n",
    "def pick_voxel_from_probabilities(probabilities):\n",
    "    return pick_weighted_random(probabilities)\n",
    "\n",
    "# Construct an example sculpture using the model's current progress\n",
    "# TODO: Move this to a separate file so we can do multithreading and other improvements\n",
    "def build_sculpture(count, base=None, temperature=1.0, debug=False):\n",
    "    # If a base wasn't specified, create one\n",
    "    color = int(random.random() * 254) + 1\n",
    "    voxels = {}\n",
    "    start_pos = (0, 0, 0)\n",
    "    # start_pos = (int(random.random() * training.SIZE[0]), int(random.random() * training.SIZE[1]), int(random.random() * training.SIZE[2]))\n",
    "    voxels[vec.ttos(start_pos)] = color\n",
    "    \n",
    "    # Build context vector for the sculpture\n",
    "    context = [(start_pos, color)]\n",
    "\n",
    "    for i in range(count-1):\n",
    "        # Determine where the next voxel will go\n",
    "        # TODO: Encode this data into the model somehow\n",
    "        next_pos = training.pick_next_voxel(voxels, context)\n",
    "\n",
    "        # Get the output from the model\n",
    "        input_data = encode_training_input(context)\n",
    "        input_data.pop(-1)\n",
    "        input_tensor = tf.Variable(input_data, tf.float64)\n",
    "        input_tensor = tf.reshape(input_tensor, [1, -1, EMBEDDING_SIZE])\n",
    "\n",
    "        input_next_pos_data = encode_training_input_next_pos(context, next_pos)\n",
    "\n",
    "        if debug:\n",
    "            print(\"Next Pos indices: \", end=\" \")\n",
    "            for i in range(len(input_next_pos_data)):\n",
    "                for j in range(EMBEDDING_SIZE):\n",
    "                    if int(input_next_pos_data[i][j]) > 0:\n",
    "                        print(j, end=\" \")\n",
    "                        break\n",
    "                    if j > 255:\n",
    "                        print(\"No\", end=\" \")\n",
    "                        break\n",
    "            print()\n",
    "\n",
    "        input_next_pos_data.pop(-1)\n",
    "        input_next_pos_tensor = tf.Variable(input_next_pos_data, tf.float64)\n",
    "        input_next_pos_tensor = tf.reshape(input_tensor, [1, -1, EMBEDDING_SIZE])\n",
    "\n",
    "        output = model([input_tensor, input_next_pos_tensor], training=False)\n",
    "        if debug:\n",
    "            print(f\"Context index: {len(context)-1}\")\n",
    "            print(f\"Context at index: {context[len(context)-1]}\")\n",
    "        output_probabilities = output[0][len(context)-1]\n",
    "\n",
    "        # Pick which voxel to generate based on output probabilities\n",
    "        # TODO: Implement temperature\n",
    "        chosen_voxel = pick_voxel_from_probabilities(output_probabilities)\n",
    "\n",
    "        if debug:\n",
    "            print(f\"Chosen voxel: {float(chosen_voxel)}\")\n",
    "        \n",
    "        # Build the voxel\n",
    "        voxels[vec.ttos(next_pos)] = chosen_voxel\n",
    "        context.append((next_pos, chosen_voxel))\n",
    "        if len(context) > CONTEXT_SIZE:\n",
    "            context = training.remove_farthest(context, next_pos)\n",
    "        \n",
    "        if debug:\n",
    "            print()\n",
    "        \n",
    "    return voxels\n",
    "\n",
    "def build_sculpture_test(count, base=None, temperature=1.0, debug=True):\n",
    "    te = training_examples[0]\n",
    "\n",
    "    # If a base wasn't specified, create one\n",
    "    color = te[0][1]\n",
    "    voxels = {}\n",
    "    start_pos = te[0][0]\n",
    "    # start_pos = (int(random.random() * training.SIZE[0]), int(random.random() * training.SIZE[1]), int(random.random() * training.SIZE[2]))\n",
    "    voxels[vec.ttos(start_pos)] = color\n",
    "    \n",
    "    # Build context vector for the sculpture\n",
    "    context = [(start_pos, color)]\n",
    "\n",
    "    for i in range(min(count-1, CONTEXT_SIZE)):\n",
    "        # Determine where the next voxel will go\n",
    "        # TODO: Encode this data into the model somehow\n",
    "        next_pos = te[i+1][0]\n",
    "\n",
    "        # Get the output from the model\n",
    "        input_data = encode_training_input(context)\n",
    "        input_data.pop(-1)\n",
    "        input_tensor = tf.Variable(input_data, tf.float64)\n",
    "        input_tensor = tf.reshape(input_tensor, [1, -1, EMBEDDING_SIZE])\n",
    "\n",
    "        input_next_pos_data = encode_training_input_next_pos(context, next_pos)\n",
    "\n",
    "        input_next_pos_data.pop(-1)\n",
    "        input_next_pos_tensor = tf.Variable(input_next_pos_data, tf.float64)\n",
    "        input_next_pos_tensor = tf.reshape(input_tensor, [1, -1, EMBEDDING_SIZE])\n",
    "\n",
    "        output = model([input_tensor, input_next_pos_tensor], training=False)\n",
    "        output_probabilities = output[0][len(context)-1]\n",
    "\n",
    "        # Pick which voxel to generate based on output probabilities\n",
    "        # TODO: Implement temperature\n",
    "        chosen_voxel = pick_voxel_from_probabilities(output_probabilities)\n",
    "        correct_voxel = te[i+1][1]\n",
    "\n",
    "        if chosen_voxel == correct_voxel:\n",
    "            print(f\"Correct Inference: {chosen_voxel}\")\n",
    "        else:\n",
    "            print(f\"Incorrect: {chosen_voxel} should be {correct_voxel}\")\n",
    "        \n",
    "        # Build the voxel\n",
    "        voxels[vec.ttos(next_pos)] = correct_voxel\n",
    "        context = te[:i+1]\n",
    "        \n",
    "    return voxels\n",
    "\n",
    "build_sculpture(15, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for saving sculptures to json\n",
    "def save_sculpture(sculpture, filename):\n",
    "    json_data = {\n",
    "        \"size\": {\n",
    "            \"x\": training.SIZE[0],\n",
    "            \"y\": training.SIZE[1],\n",
    "            \"z\": training.SIZE[2],\n",
    "        },\n",
    "        \"voxels\": sculpture,\n",
    "    }\n",
    "    with open(filename, 'w') as output_file:\n",
    "        json.dump(json_data, output_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 525\n",
      "Building example sculpture...\n",
      "Done\n",
      "Epoch 973\n",
      "Building example sculpture...\n",
      "Done\n",
      "Epoch 1853\n",
      "Building example sculpture...\n",
      "Done\n",
      "Epoch 3277\n",
      "Building example sculpture...\n",
      "Done\n",
      "Epoch 5398\n",
      "Building example sculpture...\n",
      "Done\n",
      "Epoch 8448\n",
      "Building example sculpture...\n",
      "Done\n",
      "Epoch 12714\n",
      "Building example sculpture...\n",
      "Done\n",
      "Epoch 18308\n",
      "Building example sculpture...\n",
      "Done\n",
      "Epoch 26120\n",
      "Building example sculpture...\n",
      "Done\n",
      "Epoch 36525\n",
      "Building example sculpture...\n",
      "Done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\dev\\VoxelGPT\\run_train.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m       \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m       example_time \u001b[39m=\u001b[39m (datetime\u001b[39m.\u001b[39mnow()\u001b[39m-\u001b[39mtime_started)\u001b[39m.\u001b[39mtotal_seconds() \u001b[39m*\u001b[39m \u001b[39m1.3\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m train(\u001b[39m10000000\u001b[39;49m)\n",
      "\u001b[1;32md:\\dev\\VoxelGPT\\run_train.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Epochs\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m   \u001b[39m# Minibatches\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m   \u001b[39mfor\u001b[39;00m (batch_input, batch_input_next_pos, batch_output) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39;49m(training_input_batched, training_input_next_pos_batched, training_output_batched):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     train_step(batch_input, batch_input_next_pos, batch_output)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# print(float(train_step(batch_input, batch_input_next_pos, batch_output)))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m   \u001b[39m# Print status\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m   \u001b[39m# print(f\"Completed Epoch {epoch}\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/VoxelGPT/run_train.ipynb#Y102sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m   \u001b[39m# Check if we should output an example sculpture\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:499\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m ops\u001b[39m.\u001b[39minside_function():\n\u001b[0;32m    498\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 499\u001b[0m     \u001b[39mreturn\u001b[39;00m iterator_ops\u001b[39m.\u001b[39;49mOwnedIterator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    500\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    501\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39miteration in eager mode or within tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:696\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m (components \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m element_spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    694\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    695\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot be specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 696\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_iterator(dataset)\n\u001b[0;32m    698\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next_call_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:718\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_shapes \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mget_flat_tensor_shapes(\n\u001b[0;32m    715\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec)\n\u001b[0;32m    716\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(ds_variant):\n\u001b[0;32m    717\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_resource \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 718\u001b[0m       gen_dataset_ops\u001b[39m.\u001b[39;49manonymous_iterator_v3(\n\u001b[0;32m    719\u001b[0m           output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[0;32m    720\u001b[0m           output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes))\n\u001b[0;32m    721\u001b[0m   gen_dataset_ops\u001b[39m.\u001b[39mmake_iterator(ds_variant, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_resource)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:202\u001b[0m, in \u001b[0;36manonymous_iterator_v3\u001b[1;34m(output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m    201\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m    203\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mAnonymousIteratorV3\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types,\n\u001b[0;32m    204\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m    206\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training step\n",
    "@tf.function\n",
    "def train_step(input_data, input_next_pos_data, output_data):\n",
    "    # Set up tape\n",
    "    with tf.GradientTape() as tape:\n",
    "      output = model([input_data, input_next_pos_data], training=True)\n",
    "\n",
    "      loss = loss_function(output_data, output)\n",
    "\n",
    "      gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "      return loss\n",
    "\n",
    "# Training loop\n",
    "def train(epochs):\n",
    "  time_started = datetime.now()\n",
    "  example_time = 3\n",
    "  sculptures_made = 0\n",
    "\n",
    "  # Epochs\n",
    "  for epoch in range(epochs):\n",
    "    # Minibatches\n",
    "    for (batch_input, batch_input_next_pos, batch_output) in zip(training_input_batched, training_input_next_pos_batched, training_output_batched):\n",
    "      train_step(batch_input, batch_input_next_pos, batch_output)\n",
    "      # print(float(train_step(batch_input, batch_input_next_pos, batch_output)))\n",
    "\n",
    "    # Print status\n",
    "    # print(f\"Completed Epoch {epoch}\")\n",
    "\n",
    "    # Check if we should output an example sculpture\n",
    "    if (datetime.now()-time_started).total_seconds() >= example_time:\n",
    "      print(f\"Epoch {epoch}\")\n",
    "      print(\"Building example sculpture...\")\n",
    "      sculpture = build_sculpture(training.SIZE[0] * training.SIZE[1] * training.SIZE[2])\n",
    "      # sculpture = build_sculpture(300)\n",
    "      sculptures_made += 1\n",
    "      sculpture_filename = f\"examples/json/example_{(time_started-datetime.utcfromtimestamp(0)).total_seconds()}_{sculptures_made}.json\"\n",
    "      save_sculpture(sculpture, sculpture_filename)\n",
    "      print(\"Done\")\n",
    "      example_time = (datetime.now()-time_started).total_seconds() * 1.3\n",
    "\n",
    "train(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('nextpostest.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
