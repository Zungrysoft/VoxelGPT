{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in Google Colab, download all of this repo's files\n",
    "import os\n",
    "import zipfile\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    repo_url = \"https://github.com/Zungrysoft/VoxelGPT/archive/refs/heads/master.zip\"\n",
    "    response = urlopen(repo_url)\n",
    "    zip_content = response.read()\n",
    "    with BytesIO(zip_content) as zip_file:\n",
    "            with zipfile.ZipFile(zip_file) as z:\n",
    "                z.extractall(\"/content/\")\n",
    "\n",
    "    !mv -vf /content/VoxelGPT-master/* /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import json\n",
    "import training\n",
    "import color\n",
    "import render\n",
    "import vector as vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# Network Structure\n",
    "CONTEXT_SIZE = 32       # How many other voxels are considered for a training example\n",
    "EMBEDDING_SIZE = 520    # Dimensionality of the voxel embedding vector\n",
    "STACKED_LAYERS = 1      # How many times the network structure repeats itself\n",
    "ATTENTION_HEADS = 10    # Number of heads in each multi-headed attention mechanism\n",
    "\n",
    "# Training Hyperparameters\n",
    "CHECK_RADIUS = 7        # How far away voxels can be to be part of a training example\n",
    "CENTER_FOCUS = 0.3      # How much to focus on picking voxels close to the center of the cube. Must be between 0 and 1.\n",
    "LEARNING_RATE = 1e-3\n",
    "AIR_WEIGHT = 9\n",
    "\n",
    "# Training data\n",
    "BATCH_SIZE = 128\n",
    "TRAINING_EXAMPLES = BATCH_SIZE * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palette has 256 colors\n"
     ]
    }
   ],
   "source": [
    "# Load voxel palette\n",
    "# The output is a 255-dimensional vector of probabilities for different colors\n",
    "# Which 255 colors can be generated is decided by the palette file\n",
    "\n",
    "# Index 0 is reserved as 'undecided' voxel\n",
    "# Index 1 is reserved as 'air' voxel\n",
    "# Index 2-255 are colors. So there are 254 possible colors.\n",
    "palette = color.load_palette()\n",
    "palette_size = len(palette)\n",
    "\n",
    "print(f\"Palette has {palette_size} colors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 32, 520)]    0           []                               \n",
      "                                                                                                  \n",
      " normalization_start_a (LayerNo  (None, 32, 520)     1040        ['input[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_0 (MultiH  (None, 32, 520)     10832120    ['normalization_start_a[0][0]',  \n",
      " eadAttention)                                                    'normalization_start_a[0][0]']  \n",
      "                                                                                                  \n",
      " residual_connection_0a (Add)   (None, 32, 520)      0           ['normalization_start_a[0][0]',  \n",
      "                                                                  'multi_head_attention_0[0][0]'] \n",
      "                                                                                                  \n",
      " normalization_0a (LayerNormali  (None, 32, 520)     1040        ['residual_connection_0a[0][0]'] \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " feedforward_0 (Dense)          (None, 32, 520)      270920      ['normalization_0a[0][0]']       \n",
      "                                                                                                  \n",
      " relu_0 (LeakyReLU)             (None, 32, 520)      0           ['feedforward_0[0][0]']          \n",
      "                                                                                                  \n",
      " residual_connection_0b (Add)   (None, 32, 520)      0           ['normalization_0a[0][0]',       \n",
      "                                                                  'relu_0[0][0]']                 \n",
      "                                                                                                  \n",
      " normalization_0b (LayerNormali  (None, 32, 520)     1040        ['residual_connection_0b[0][0]'] \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " feedforward_final (Dense)      (None, 32, 255)      132855      ['normalization_0b[0][0]']       \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 32, 255)      0           ['feedforward_final[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,239,015\n",
      "Trainable params: 11,239,015\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "def main_model():\n",
    "    input = keras.Input(shape=(CONTEXT_SIZE, EMBEDDING_SIZE,), name='input')\n",
    "\n",
    "    # Normalization\n",
    "    x = keras.layers.LayerNormalization(name=f'normalization_start_a')(input)\n",
    "\n",
    "    # Stacked layers\n",
    "    for i in range(STACKED_LAYERS):\n",
    "        # Multi-headed attention\n",
    "        fx = keras.layers.MultiHeadAttention(\n",
    "            num_heads=ATTENTION_HEADS,\n",
    "            key_dim=EMBEDDING_SIZE,\n",
    "            name=f'multi_head_attention_{i}',\n",
    "        )(x, x, use_causal_mask=True)\n",
    "\n",
    "        # Residual connection\n",
    "        x = keras.layers.Add(name=f'residual_connection_{i}a')([x,fx])\n",
    "\n",
    "        # Normalization\n",
    "        x = keras.layers.LayerNormalization(name=f'normalization_{i}a')(x)\n",
    "\n",
    "        # Feedforward\n",
    "        fx = keras.layers.Dense(EMBEDDING_SIZE, name=f'feedforward_{i}')(x)\n",
    "        fx = keras.layers.LeakyReLU(name=f'relu_{i}')(fx)\n",
    "\n",
    "        # Residual connection\n",
    "        x = keras.layers.Add(name=f'residual_connection_{i}b')([x,fx])\n",
    "\n",
    "        # Normalization\n",
    "        x = keras.layers.LayerNormalization(name=f'normalization_{i}b')(x)\n",
    "\n",
    "    # Final feedforward layer\n",
    "    # Output size should be palette_size-1, since we don't want it to be able to choose \"undecided\"\n",
    "    x = keras.layers.Dense(palette_size-1, name='feedforward_final')(x)\n",
    "\n",
    "    # Softmax\n",
    "    x = keras.layers.Softmax(name='softmax')(x)\n",
    "    \n",
    "    # Build and return model\n",
    "    return keras.Model(inputs=[input, ], outputs=x)\n",
    "\n",
    "model = main_model()\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design training examples\n",
    "training_examples = training.generate_training_examples(TRAINING_EXAMPLES, CONTEXT_SIZE)\n",
    "\n",
    "print(f\"{len(training_examples)} training examples created.\")\n",
    "\n",
    "print(random.choice(training_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_training_input(example):\n",
    "    inputEntry = []\n",
    "\n",
    "    # Encode context vector\n",
    "    for index, voxel in enumerate(example):\n",
    "        if len(inputEntry) < CONTEXT_SIZE+1:\n",
    "            inputEntry.append(training.embed(index, voxel[0], voxel[1], palette, EMBEDDING_SIZE))\n",
    "\n",
    "    # Pad remainder of context with zeros\n",
    "    if len(inputEntry) < CONTEXT_SIZE+1:\n",
    "        zero_elem = [0,] * EMBEDDING_SIZE\n",
    "        inputEntry += [zero_elem,] * ((CONTEXT_SIZE+1) - len(inputEntry))\n",
    "\n",
    "    return inputEntry\n",
    "\n",
    "def encode_training_output(example):\n",
    "    outputEntry = []\n",
    "    for voxel in example:\n",
    "        outputEntry.append(training.encode_one_hot(voxel[1], palette_size))\n",
    "    return outputEntry\n",
    "\n",
    "# Reformat training examples into tensor format\n",
    "def encode_training_examples(training_examples):\n",
    "    training_inputs = []\n",
    "    training_outputs = []\n",
    "    for example in training_examples:\n",
    "        input_entry = encode_training_input(example)\n",
    "        output_entry = encode_training_output(example)\n",
    "        \n",
    "        # Shift the output\n",
    "        input_entry.pop(-1)\n",
    "        output_entry.pop(0)\n",
    "\n",
    "        # Push to training example list\n",
    "        training_inputs.append(input_entry)\n",
    "        training_outputs.append(output_entry)\n",
    "\n",
    "    training_input_tensor = tf.Variable(training_inputs, tf.float64)\n",
    "    training_output_tensor = tf.Variable(training_outputs, tf.float64)\n",
    "\n",
    "    return training_input_tensor, training_output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_tensor, training_output_tensor = encode_training_examples(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch training data\n",
    "dataset_input = tf.data.Dataset.from_tensor_slices(training_input_tensor)\n",
    "dataset_output = tf.data.Dataset.from_tensor_slices(training_output_tensor)\n",
    "\n",
    "training_input_batched = dataset_input.batch(BATCH_SIZE)\n",
    "training_output_batched = dataset_output.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_weighted_random(probabilities):\n",
    "    choice = random.random()\n",
    "    for i in range(len(probabilities)):\n",
    "        choice -= probabilities[i]\n",
    "        if choice < 0:\n",
    "            return i + 1\n",
    "    return 1\n",
    "\n",
    "def pick_highest(probabilities):\n",
    "    chosen_voxel = 1\n",
    "    best = 0\n",
    "    for i in range(len(probabilities)):\n",
    "        if probabilities[i] > best:\n",
    "            best = probabilities[i]\n",
    "            chosen_voxel = i+1\n",
    "    \n",
    "    return chosen_voxel\n",
    "\n",
    "def pick_voxel_from_probabilities(probabilities):\n",
    "    return pick_weighted_random(probabilities)\n",
    "\n",
    "# Construct an example sculpture using the model's current progress\n",
    "# TODO: Move this to a separate file so we can do multithreading and other improvements\n",
    "def build_sculpture(count, base=None, base_voxels=140, temperature=1.0, debug=False):\n",
    "    # If a base wasn't specified, create one\n",
    "    color = int(random.random() * 254) + 1\n",
    "    # color = 1\n",
    "    voxels = {}\n",
    "    start_pos = (0, 0, 0)\n",
    "    # start_pos = (int(random.random() * training.SIZE[0]), int(random.random() * training.SIZE[1]), int(random.random() * training.SIZE[2]))\n",
    "    voxels[vec.ttos(start_pos)] = color\n",
    "    \n",
    "    # Build context vector for the sculpture\n",
    "    context = [(start_pos, color)]\n",
    "\n",
    "    for i in range(count-1):\n",
    "        # Determine where the next voxel will go\n",
    "        # TODO: Encode this data into the model somehow\n",
    "        next_pos = training.pick_next_voxel(voxels, context)\n",
    "\n",
    "        if i < base_voxels and base != None:\n",
    "            # Get the voxel from the sculpture\n",
    "            pos_str = vec.ttos(next_pos)\n",
    "            if pos_str in base:\n",
    "                chosen_voxel = base[pos_str]\n",
    "            else:\n",
    "                chosen_voxel = 1\n",
    "\n",
    "            # Build the voxel\n",
    "            voxels[vec.ttos(next_pos)] = chosen_voxel\n",
    "            context.append((next_pos, chosen_voxel))\n",
    "            if len(context) > CONTEXT_SIZE:\n",
    "                context = training.remove_farthest(context, next_pos)\n",
    "        else:\n",
    "            # Get the output from the model\n",
    "            input_data = encode_training_input(context)\n",
    "            input_data.pop(-1)\n",
    "            input_tensor = tf.Variable(input_data, tf.float64)\n",
    "            input_tensor = tf.reshape(input_tensor, [1, -1, EMBEDDING_SIZE])\n",
    "\n",
    "            output = model([input_tensor], training=False)\n",
    "            if debug:\n",
    "                print(f\"Context index: {len(context)-1}\")\n",
    "                print(f\"Context at index: {context[len(context)-1]}\")\n",
    "            output_probabilities = output[0][len(context)-1]\n",
    "\n",
    "            # Pick which voxel to generate based on output probabilities\n",
    "            # TODO: Implement temperature\n",
    "            chosen_voxel = pick_voxel_from_probabilities(output_probabilities)\n",
    "\n",
    "            if debug:\n",
    "                print(f\"Chosen voxel: {float(chosen_voxel)}\")\n",
    "            \n",
    "            # Build the voxel\n",
    "            voxels[vec.ttos(next_pos)] = chosen_voxel\n",
    "            context.append((next_pos, chosen_voxel))\n",
    "            if len(context) > CONTEXT_SIZE:\n",
    "                context = training.remove_farthest(context, next_pos)\n",
    "            \n",
    "            if debug:\n",
    "                print()\n",
    "\n",
    "        \n",
    "    return voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for saving sculptures to json\n",
    "def save_sculpture(sculpture, filename):\n",
    "    json_data = {\n",
    "        \"size\": {\n",
    "            \"x\": training.SIZE[0],\n",
    "            \"y\": training.SIZE[1],\n",
    "            \"z\": training.SIZE[2],\n",
    "        },\n",
    "        \"voxels\": sculpture,\n",
    "    }\n",
    "    with open(filename, 'w') as output_file:\n",
    "        json.dump(json_data, output_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step\n",
    "@tf.function\n",
    "def train_step(input_data, output_data):\n",
    "    # Set up tape\n",
    "    with tf.GradientTape() as tape:\n",
    "      output = model([input_data], training=True)\n",
    "\n",
    "      loss = loss_function(output_data, output)\n",
    "\n",
    "      gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "      return loss\n",
    "\n",
    "# Training loop\n",
    "def train(epochs):\n",
    "  time_started = datetime.now()\n",
    "  example_time = 3\n",
    "  sculptures_made = 0\n",
    "\n",
    "  # Epochs\n",
    "  for epoch in range(epochs):\n",
    "    # Minibatches\n",
    "    for (batch_input, batch_output) in zip(training_input_batched, training_output_batched):\n",
    "      train_step(batch_input, batch_output)\n",
    "\n",
    "    # Print status\n",
    "    # print(f\"Completed Epoch {epoch}\")\n",
    "\n",
    "    # Check if we should output an example sculpture\n",
    "    if (datetime.now()-time_started).total_seconds() >= example_time:\n",
    "      print(f\"Epoch {epoch}\")\n",
    "      print(\"Building example sculpture...\")\n",
    "      sculpture = build_sculpture(training.SIZE[0] * training.SIZE[1] * training.SIZE[2])\n",
    "      # sculpture = build_sculpture(300)\n",
    "      sculptures_made += 1\n",
    "      save_time = (time_started-datetime.utcfromtimestamp(0)).total_seconds()\n",
    "      sculpture_filename = f\"examples/json/example_{save_time}_{sculptures_made}.json\"\n",
    "      save_sculpture(sculpture, sculpture_filename)\n",
    "      model.save(f\"backups/backup_{save_time}_{sculptures_made}.h5\")\n",
    "      render.plot_voxel(sculpture)\n",
    "      print(\"Done\")\n",
    "      example_time = (datetime.now()-time_started).total_seconds() * 1.3\n",
    "\n",
    "train(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training/json/juice.json\") as base_model_file:\n",
    "    base_model = json.load(base_model_file)[\"voxels\"]\n",
    "    for i in range(5):\n",
    "        sculpture = build_sculpture(training.SIZE[0] * training.SIZE[1] * training.SIZE[2], base=base_model, base_voxels=147)\n",
    "        save_sculpture(sculpture, f\"examples/json/test{i}.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
