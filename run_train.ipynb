{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import math\n",
    "import json\n",
    "import training\n",
    "import color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# Network Structure\n",
    "CONTEXT_SIZE = 5      # How many other voxels are considered for a training example\n",
    "EMBEDDING_SIZE = 520    # Dimensionality of the voxel embedding vector\n",
    "STACKED_LAYERS = 1      # How many times the network structure repeats itself\n",
    "ATTENTION_HEADS = 10    # Number of heads in each multi-headed attention mechanism\n",
    "\n",
    "# Training Hyperparameters\n",
    "CHECK_RADIUS = 7        # How far away voxels can be to be part of a training example\n",
    "CENTER_FOCUS = 0.3      # How much to focus on picking voxels close to the center of the cube. Must be between 0 and 1.\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAINING_EXAMPLES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palette has 256 colors\n"
     ]
    }
   ],
   "source": [
    "# Load voxel palette\n",
    "# The output is a 255-dimensional vector of probabilities for different colors\n",
    "# Which 255 colors can be generated is decided by the palette file\n",
    "\n",
    "# Index 0 is reserved as 'undecided' voxel\n",
    "# Index 1 is reserved as 'air' voxel\n",
    "# Index 2-255 are colors. So there are 254 possible colors.\n",
    "with open('data/palette.json', 'r') as json_file:\n",
    "    raw_palette = json.load(json_file)['colors']\n",
    "    palette = color.expand_palette(raw_palette)\n",
    "    palette_size = len(palette)\n",
    "\n",
    "print(f\"Palette has {palette_size} colors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 5, 520)]     0           []                               \n",
      "                                                                                                  \n",
      " normalization_start_a (LayerNo  (None, 5, 520)      1040        ['input[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_0 (MultiH  (None, 5, 520)      10832120    ['normalization_start_a[0][0]',  \n",
      " eadAttention)                                                    'normalization_start_a[0][0]']  \n",
      "                                                                                                  \n",
      " residual_connection_0a (Add)   (None, 5, 520)       0           ['normalization_start_a[0][0]',  \n",
      "                                                                  'multi_head_attention_0[0][0]'] \n",
      "                                                                                                  \n",
      " normalization_0a (LayerNormali  (None, 5, 520)      1040        ['residual_connection_0a[0][0]'] \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " feedforward_0 (Dense)          (None, 5, 520)       270920      ['normalization_0a[0][0]']       \n",
      "                                                                                                  \n",
      " relu_0 (LeakyReLU)             (None, 5, 520)       0           ['feedforward_0[0][0]']          \n",
      "                                                                                                  \n",
      " residual_connection_0b (Add)   (None, 5, 520)       0           ['normalization_0a[0][0]',       \n",
      "                                                                  'relu_0[0][0]']                 \n",
      "                                                                                                  \n",
      " normalization_0b (LayerNormali  (None, 5, 520)      1040        ['residual_connection_0b[0][0]'] \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " input_next_pos (InputLayer)    [(None, 5, 520)]     0           []                               \n",
      "                                                                                                  \n",
      " concatenate_next_pos (Concaten  (None, 5, 1040)     0           ['normalization_0b[0][0]',       \n",
      " ate)                                                             'input_next_pos[0][0]']         \n",
      "                                                                                                  \n",
      " feedforward_final (Dense)      (None, 5, 255)       265455      ['concatenate_next_pos[0][0]']   \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 5, 255)       0           ['feedforward_final[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,371,615\n",
      "Trainable params: 11,371,615\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "def main_model():\n",
    "    input = keras.Input(shape=(CONTEXT_SIZE, EMBEDDING_SIZE,), name='input')\n",
    "    input_next_pos = keras.Input(shape=(CONTEXT_SIZE, EMBEDDING_SIZE,), name='input_next_pos')\n",
    "\n",
    "    # Normalization\n",
    "    x = keras.layers.LayerNormalization(name=f'normalization_start_a')(input)\n",
    "\n",
    "    # Stacked layers\n",
    "    for i in range(STACKED_LAYERS):\n",
    "        # Multi-headed attention\n",
    "        fx = keras.layers.MultiHeadAttention(\n",
    "            num_heads=ATTENTION_HEADS,\n",
    "            key_dim=EMBEDDING_SIZE,\n",
    "            name=f'multi_head_attention_{i}',\n",
    "        )(x, x, use_causal_mask=True)\n",
    "\n",
    "        # Residual connection\n",
    "        x = keras.layers.Add(name=f'residual_connection_{i}a')([x,fx])\n",
    "\n",
    "        # Normalization\n",
    "        x = keras.layers.LayerNormalization(name=f'normalization_{i}a')(x)\n",
    "\n",
    "        # Feedforward\n",
    "        fx = keras.layers.Dense(EMBEDDING_SIZE, name=f'feedforward_{i}')(x)\n",
    "        fx = keras.layers.LeakyReLU(name=f'relu_{i}')(fx)\n",
    "\n",
    "        # Residual connection\n",
    "        x = keras.layers.Add(name=f'residual_connection_{i}b')([x,fx])\n",
    "\n",
    "        # Normalization\n",
    "        x = keras.layers.LayerNormalization(name=f'normalization_{i}b')(x)\n",
    "    \n",
    "    # Concatenate with next_pos input\n",
    "    x = keras.layers.Concatenate(axis=2, name='concatenate_next_pos')([x,input_next_pos])\n",
    "\n",
    "    # Final feedforward layer\n",
    "    # Output size should be palette_size-1, since we don't want it to be able to choose \"undecided\"\n",
    "    x = keras.layers.Dense(palette_size-1, name='feedforward_final')(x)\n",
    "\n",
    "    # Softmax\n",
    "    x = keras.layers.Softmax(name='softmax')(x)\n",
    "    \n",
    "    # Build and return model\n",
    "    return keras.Model(inputs=[input, input_next_pos], outputs=x)\n",
    "\n",
    "model = main_model()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loss and optimizer\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 training examples created.\n",
      "[((0, 2, 5), 231), ((1, 2, 5), 1), ((2, 2, 5), 1), ((4, 4, 4), 231), ((4, 5, 4), 1), ((4, 4, 5), 231)]\n"
     ]
    }
   ],
   "source": [
    "# Design training examples\n",
    "training_examples = training.generate_training_examples(TRAINING_EXAMPLES, CONTEXT_SIZE)\n",
    "\n",
    "print(f\"{len(training_examples)} training examples created.\")\n",
    "\n",
    "print(random.choice(training_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.0000000e+00  1.0000000e+00  0.0000000e+00 ...  1.0000000e+00\n",
      "   6.2099438e-08  1.0000000e+00]\n",
      " [ 8.4147096e-01  5.4030228e-01  7.2094172e-01 ...  1.0000000e+00\n",
      "   6.2099438e-08  1.0000000e+00]\n",
      " [ 9.0929741e-01 -4.1614684e-01  9.9921900e-01 ...  1.0000000e+00\n",
      "   6.2099438e-08  1.0000000e+00]\n",
      " [-7.5680250e-01 -6.5364361e-01 -7.8966245e-02 ...  1.0000000e+00\n",
      "   4.9679549e-08  1.0000000e+00]\n",
      " [-7.5680250e-01 -6.5364361e-01 -7.8966245e-02 ...  1.0000000e+00\n",
      "   4.9679549e-08  1.0000000e+00]], shape=(5, 510), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 8.4147096e-01  5.4030228e-01  7.2094172e-01 ...  1.0000000e+00\n",
      "   6.2099438e-08  1.0000000e+00]\n",
      " [ 9.0929741e-01 -4.1614684e-01  9.9921900e-01 ...  1.0000000e+00\n",
      "   6.2099438e-08  1.0000000e+00]\n",
      " [-7.5680250e-01 -6.5364361e-01 -7.8966245e-02 ...  1.0000000e+00\n",
      "   4.9679549e-08  1.0000000e+00]\n",
      " [-7.5680250e-01 -6.5364361e-01 -7.8966245e-02 ...  1.0000000e+00\n",
      "   4.9679549e-08  1.0000000e+00]\n",
      " [-7.5680250e-01 -6.5364361e-01 -7.8966245e-02 ...  1.0000000e+00\n",
      "   6.2099438e-08  1.0000000e+00]], shape=(5, 510), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(5, 245), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "def encode_training_input(example):\n",
    "    inputEntry = []\n",
    "\n",
    "    # Encode context vector\n",
    "    for index, voxel in enumerate(example):\n",
    "        if len(inputEntry) < CONTEXT_SIZE+1:\n",
    "            inputEntry.append(training.embed(index, voxel[0], voxel[1], palette, EMBEDDING_SIZE))\n",
    "\n",
    "    # Pad remainder of context with zeros\n",
    "    if len(inputEntry) < CONTEXT_SIZE+1:\n",
    "        zero_elem = [0,] * EMBEDDING_SIZE\n",
    "        inputEntry += [zero_elem,] * ((CONTEXT_SIZE+1) - len(inputEntry))\n",
    "\n",
    "    return inputEntry\n",
    "\n",
    "def encode_training_input_next_pos(example, next_pos=None):\n",
    "    if next_pos == None:\n",
    "        inputEntry = []\n",
    "\n",
    "        # Encode context vector\n",
    "        for index, voxel in enumerate(example):\n",
    "            if len(inputEntry) < CONTEXT_SIZE+1:\n",
    "                inputEntry.append(training.embed(index, voxel[0], -1, palette, EMBEDDING_SIZE))\n",
    "\n",
    "        # Pad remainder of context with zeros\n",
    "        if len(inputEntry) < CONTEXT_SIZE+1:\n",
    "            zero_elem = [0,] * EMBEDDING_SIZE\n",
    "            inputEntry += [zero_elem,] * ((CONTEXT_SIZE+1) - len(inputEntry))\n",
    "        \n",
    "        return inputEntry\n",
    "    else:\n",
    "        # Create zero vector\n",
    "        zero_elem = [0,] * EMBEDDING_SIZE\n",
    "        inputEntry = [zero_elem,] * (CONTEXT_SIZE+1)\n",
    "\n",
    "        inputEntry[len(example)] = training.embed(len(example), next_pos, -1, palette, EMBEDDING_SIZE)\n",
    "\n",
    "        return inputEntry\n",
    "\n",
    "def encode_training_output(example):\n",
    "    outputEntry = []\n",
    "    for voxel in example:\n",
    "        outputEntry.append(training.encode_one_hot(voxel[1], palette_size))\n",
    "    return outputEntry\n",
    "\n",
    "# Reformat training examples into tensor format\n",
    "def encode_training_examples(training_examples):\n",
    "    training_inputs = []\n",
    "    training_inputs_next_pos = []\n",
    "    training_outputs = []\n",
    "    for example in training_examples:\n",
    "        input_entry = encode_training_input(example)\n",
    "        input_entry_next_pos = encode_training_input_next_pos(example)\n",
    "        output_entry = encode_training_output(example)\n",
    "        \n",
    "        # Shift the output\n",
    "        input_entry.pop(-1)\n",
    "        input_entry_next_pos.pop(0)\n",
    "        output_entry.pop(0)\n",
    "\n",
    "        # Push to training example list\n",
    "        training_inputs.append(input_entry)\n",
    "        training_inputs_next_pos.append(input_entry_next_pos)\n",
    "        training_outputs.append(output_entry)\n",
    "\n",
    "    training_input_tensor = tf.Variable(training_inputs, tf.float64)\n",
    "    training_input_next_pos_tensor = tf.Variable(training_inputs_next_pos, tf.float64)\n",
    "    training_output_tensor = tf.Variable(training_outputs, tf.float64)\n",
    "\n",
    "    return training_input_tensor, training_input_next_pos_tensor, training_output_tensor\n",
    "\n",
    "training_input_tensor, training_input_next_pos_tensor, training_output_tensor = encode_training_examples(training_examples)\n",
    "\n",
    "# print(training_input_tensor[0, :, 10:])\n",
    "# print(training_input_next_pos_tensor[0, :, 10:])\n",
    "# print(training_output_tensor[0, :, 10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch training data\n",
    "dataset_input = tf.data.Dataset.from_tensor_slices(training_input_tensor)\n",
    "dataset_input_next_pos = tf.data.Dataset.from_tensor_slices(training_input_next_pos_tensor)\n",
    "dataset_output = tf.data.Dataset.from_tensor_slices(training_output_tensor)\n",
    "\n",
    "training_input_batched = dataset_input.batch(128)\n",
    "training_input_next_pos_batched = dataset_input_next_pos.batch(128)\n",
    "training_output_batched = dataset_output.batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct an example sculpture using the model's current progress\n",
    "# TODO: Move this to a separate file so we can do multithreading and other improvements\n",
    "def build_sculpture(count, base=None, temperature=1.0):\n",
    "    # If a base wasn't specified, create one\n",
    "    color = int(random.random() * 254) + 1\n",
    "    voxels = {}\n",
    "    # start_pos = (0, 0, 0)\n",
    "    start_pos = (int(random.random() * training.SIZE[0]), int(random.random() * training.SIZE[1]), int(random.random() * training.SIZE[2]))\n",
    "    voxels[training.ttos(start_pos)] = color\n",
    "    \n",
    "    # Build context vector for the sculpture\n",
    "    context = [(start_pos, color)]\n",
    "\n",
    "    for i in range(count-1):\n",
    "        # Determine where the next voxel will go\n",
    "        # TODO: Encode this data into the model somehow\n",
    "        next_pos = training.pick_next_voxel(voxels, context)\n",
    "\n",
    "        # Get the output from the model\n",
    "        input_data = encode_training_input(context)\n",
    "        input_data.pop(-1)\n",
    "        input_tensor = tf.Variable(input_data, tf.float64)\n",
    "        input_tensor = tf.reshape(input_tensor, [1, -1, EMBEDDING_SIZE])\n",
    "\n",
    "        input_next_pos_data = encode_training_input_next_pos(context, next_pos)\n",
    "        input_next_pos_data.pop(0)\n",
    "        input_next_pos_tensor = tf.Variable(input_next_pos_data, tf.float64)\n",
    "        input_next_pos_tensor = tf.reshape(input_tensor, [1, -1, EMBEDDING_SIZE])\n",
    "\n",
    "        output = model([input_tensor, input_next_pos_tensor], training=False)\n",
    "        output_probabilities = output[0][len(context)-1]\n",
    "\n",
    "        # Pick which voxel to generate based on output probabilities\n",
    "        # TODO: Implement temperature\n",
    "        choice = random.random()\n",
    "        chosen_voxel = 1\n",
    "        for i in range(len(output_probabilities)):\n",
    "            choice -= output_probabilities[i]\n",
    "            if choice < 0:\n",
    "                chosen_voxel = i+1\n",
    "                break\n",
    "        # chosen_voxel = 1\n",
    "        # best = 0\n",
    "        # for i in range(len(output_probabilities)):\n",
    "        #     if output_probabilities[i] > best:\n",
    "        #         best = output_probabilities[i]\n",
    "        #         chosen_voxel = i+1\n",
    "        \n",
    "        # Build the voxel\n",
    "        voxels[training.ttos(next_pos)] = chosen_voxel\n",
    "        context.append((next_pos, chosen_voxel))\n",
    "        if len(context) > CONTEXT_SIZE:\n",
    "            context = training.remove_farthest(context, next_pos)\n",
    "        \n",
    "    return voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for saving sculptures to json\n",
    "def save_sculpture(sculpture, filename):\n",
    "    json_data = {\n",
    "        \"size\": {\n",
    "            \"x\": training.SIZE[0],\n",
    "            \"y\": training.SIZE[1],\n",
    "            \"z\": training.SIZE[2],\n",
    "        },\n",
    "        \"voxels\": sculpture,\n",
    "    }\n",
    "    with open(filename, 'w') as output_file:\n",
    "        json.dump(json_data, output_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step\n",
    "@tf.function\n",
    "def train_step(input_data, input_next_pos_data, output_data):\n",
    "    # Set up tape\n",
    "    with tf.GradientTape() as tape:\n",
    "      output = model([input_data, input_next_pos_data], training=True)\n",
    "\n",
    "      loss = loss_function(output_data, output)\n",
    "\n",
    "      gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "# Training loop\n",
    "def train(epochs):\n",
    "  time_started = datetime.now()\n",
    "  example_time = 3\n",
    "  sculptures_made = 0\n",
    "\n",
    "  # Epochs\n",
    "  for epoch in range(epochs):\n",
    "    # Minibatches\n",
    "    for (batch_input, batch_input_next_pos, batch_output) in zip(training_input_batched, training_input_next_pos_batched, training_output_batched):\n",
    "      train_step(batch_input, batch_input_next_pos, batch_output)\n",
    "\n",
    "    # Print status\n",
    "    # print(f\"Completed Epoch {epoch}\")\n",
    "\n",
    "    # Check if we should output an example sculpture\n",
    "    if (datetime.now()-time_started).total_seconds() >= example_time:\n",
    "      print(f\"Epoch {epoch}\")\n",
    "      print(\"Building example sculpture...\")\n",
    "      sculpture = build_sculpture(training.SIZE[0] * training.SIZE[1] * training.SIZE[2])\n",
    "      sculptures_made += 1\n",
    "      sculpture_filename = f\"examples/json/example_{(time_started-datetime.utcfromtimestamp(0)).total_seconds()}_{sculptures_made}.json\"\n",
    "      save_sculpture(sculpture, sculpture_filename)\n",
    "      print(\"Done\")\n",
    "      example_time = (datetime.now()-time_started).total_seconds() * 1.3\n",
    "\n",
    "train(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sorpok.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
